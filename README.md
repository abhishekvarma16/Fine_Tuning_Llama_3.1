Llama Fine-tuning for Sentiment Analysis
Fine-tuning implementation of Meta's Llama language model for sentiment analysis on the IMDB Movie Review Dataset.
Overview
This project demonstrates how to fine-tune the Llama model for binary sentiment classification using the IMDB Movie Review Dataset. The implementation showcases efficient fine-tuning techniques including Parameter Efficient Fine-Tuning (PEFT) and QLoRA to reduce memory requirements while maintaining performance.
Features

Fine-tune Llama model using PEFT/LoRA approaches
Memory-efficient implementation using 4-bit quantization
Sentiment analysis on IMDB movie reviews (positive/negative classification)
Training and evaluation scripts
Inference examples for using the fine-tuned model
